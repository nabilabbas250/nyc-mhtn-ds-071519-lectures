{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the packages you need\n",
    "\n",
    "import requests\n",
    "import config\n",
    "import mysql.connector \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the keys that you want into the keys1 list\n",
    "#this function will remove unneeded keys\n",
    "\n",
    "def dict_clean_businesses(df):\n",
    "    keys1 = ['id', 'vote_average', 'title', 'genre_ids', 'release_date', 'actor']\n",
    "    keys2 = list(df[0].keys())\n",
    "\n",
    "    for dictionary in df:\n",
    "        for key in keys2:\n",
    "            if key not in keys1:\n",
    "                del dictionary[key]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the genre table via api\n",
    "def genre_id():\n",
    "    parameters = {'api_key': config.api_key} #these parameters go in to the URL\n",
    "    response = requests.get('https://api.themoviedb.org/3/genre/movie/list?language=en-US', params = parameters)\n",
    "    response.status_code #check this, should be 200\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#function to obtain the movie dictionary data \"per page\"\n",
    "def api_movies():\n",
    "    parameters = {'api_key': config.api_key, 'sort_by': 'vote_average.desc', 'vote_count.gte': 100, 'page': 1, 'with_original_language': 'en'}\n",
    "    #the 'page' key in the parameters will be a variable to be looped over\n",
    "    response = requests.get('https://api.themoviedb.org/3/discover/movie', params = parameters)\n",
    "    time.sleep(1)  #pauses code for a second to prevent too many parses\n",
    "    response.status_code #status code should be 200\n",
    "    \n",
    "    return response.json()['results']\n",
    "# api_movies()\n",
    "# dict_clean_businesses(webscrape())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #Now we begin webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "html_page = requests.get('https://www.themoviedb.org/movie/'+'182560'+'/cast')\n",
    "#182560 is a movie id 'variable' that will be iterated over\n",
    "soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "#standard syntax of webscraping\n",
    "\n",
    "#1) inspect page and find the actors hightlight\n",
    "#2) select the nearest tag w/ class = *div* container\n",
    "div = soup.find('ol', class_='people credits')\n",
    "all_divs = div.findAll('div', class_='info')\n",
    "#^find 'div' tag with class=info \n",
    "#and work from there using:\n",
    "#nextSibling, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nextSibling, previousSibling, children, parent, attrs, find(), findAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Charlize Theron',\n",
       " 'Nicholas Hoult',\n",
       " 'ChloÃ« Grace Moretz',\n",
       " 'Christina Hendricks',\n",
       " 'Tye Sheridan',\n",
       " 'Corey Stoll',\n",
       " 'Andrea Roth',\n",
       " 'Sterling Jerins',\n",
       " 'Shannon Kook',\n",
       " 'Drea de Matteo',\n",
       " 'Sean Bridgers',\n",
       " 'J. Larose',\n",
       " 'Jennifer Pierce Mathus',\n",
       " 'Denise Williamson',\n",
       " 'Natalie Precht',\n",
       " 'Madison McGuire',\n",
       " 'Addy Miller',\n",
       " 'Jeff Chase',\n",
       " 'Laura Cayouette',\n",
       " 'Richard Gunn',\n",
       " 'Glenn Morshower',\n",
       " 'Lori Z. Cordova',\n",
       " 'Michael Crabtree',\n",
       " 'John F. Daniel',\n",
       " 'Steve Shearer',\n",
       " 'Dan Hewitt Owens',\n",
       " 'Gillian Flynn',\n",
       " 'Tyler Forrest',\n",
       " 'Dora Madison']"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def movie_actors():\n",
    "    \n",
    "    html_page = requests.get('https://www.themoviedb.org/movie/'+'182560'+'/cast')\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    div = soup.find('ol', class_='people credits')\n",
    "    all_divs = div.findAll('div', class_='info')\n",
    "    \n",
    "    actors = []\n",
    "    for tag in all_divs:\n",
    "        actors.append(tag.text.split('\\n')[1])\n",
    "    return actors\n",
    "movie_actors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6885'"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1000 movies \n",
    "#actors from the movies\n",
    "\n",
    "#actor_id below\n",
    "div = soup.find('ol', class_='people credits') \n",
    "all_divs = div.findAll('div', class_='info')\n",
    "all_divs[0].find('a').attrs['href'].split('/')[2].split('-')[0]\n",
    "# div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Acting'"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#steps taken to webscrape\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_page = requests.get('https://www.themoviedb.org/person/119589')\n",
    "soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "\n",
    "#inspect Donald Glover\n",
    "#acting\n",
    "div = soup.find('section', class_='facts left_column')\n",
    "div.findAll('p')\n",
    "list(div.findAll('p')[0].children)[0].text\n",
    "list(div.findAll('p')[0].children)[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acting', 'Male', '27', '1983-09-25', 'Stone Mountain, Georgia, USA']"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def actor_info():\n",
    "    html_page = requests.get('https://www.themoviedb.org/person/' + '119589')\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    div = soup.find('section', class_='facts left_column')\n",
    "    traits = []\n",
    "    for i in range(len(div.findAll('p'))-4):\n",
    "        traits.extend(list(div.findAll('p')[i].children)[1].split())\n",
    "    traits[4:8] = [' '.join(traits[4:8])]\n",
    "    \n",
    "#     traits.extend(traits[4].split(','))\n",
    "#     print(traits)\n",
    "#     del traits[4:6]\n",
    "#     del traits[5]\n",
    "#the above code is if we only want STATES (i.e. Georgia, California) the code is unfinished\n",
    "    return traits\n",
    "\n",
    "actor_info()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Acting'"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(div.findAll('p')[0].children)[1].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_divs = div.findAll('div', class_='info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import datetime\n",
    "import config\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "                host = \"rami-flatiron.ci2poaotvf7v.us-east-2.rds.amazonaws.com\",\n",
    "                user = \"admin_rami\",\n",
    "                passwd = \"oolP753cD635\",\n",
    "                database = 'movie_insights'\n",
    "                )\n",
    "c = conn.cursor()\n",
    "for i in range(38,52):\n",
    "    params = {'api_key': config.api_key, 'sort_by':'vote_average.desc', 'vote_count.gte': 100,\n",
    "              'page': i, \n",
    "              'with_original_language': 'en'}\n",
    "    base_url = config.base_url\n",
    "    response = requests.get(base_url + '/discover/movie', params = params)\n",
    "    if response.status_code != 200:\n",
    "        print(f'Break at {i}, status code: {response.status_code}')\n",
    "        break\n",
    "    \n",
    "    less_info = list(map(lambda x: {'id':x['id'], \n",
    "                                    'vote_average': x['vote_average'],\n",
    "                                    'title': x['title'],\n",
    "#                                   'genre_ids': x['genre_ids'],\n",
    "                                   },response.json()['results']))\n",
    "    \n",
    "\n",
    "    def scrape_info(movie_dict):\n",
    "        movie_id = movie_dict['id']\n",
    "        html_page = requests.get('https://www.themoviedb.org/movie/' + str(movie_id)) #Make a get request to retrieve the page\n",
    "        soup = BeautifulSoup(html_page.content, 'html.parser') #Pass the page contents to beautiful soup for parsing\n",
    "        releases = soup.find('ul', class_=\"releases\")\n",
    "        revenue = releases.nextSibling.nextSibling.nextSibling.nextSibling.nextSibling.nextSibling.nextSibling.nextSibling\n",
    "        try:\n",
    "            movie_dict['revenue'] = float(str(revenue.text).replace(revenue.strong.text, \"\").replace('$','').replace(',','').strip())\n",
    "        except:\n",
    "            movie_dict['revenue'] = None\n",
    "        budget = releases.nextSibling.nextSibling.nextSibling.nextSibling.nextSibling.nextSibling\n",
    "        try:\n",
    "            movie_dict['budget'] = float(str(budget.text).replace(budget.strong.text, \"\").replace('$','').replace(',','').strip())\n",
    "        except:\n",
    "            movie_dict['budget'] = None\n",
    "        release_date = releases.div.previous_sibling.previous_sibling.previous_sibling.replace('\\n','').strip()\n",
    "        movie_dict['release_date'] = datetime.datetime.strptime(release_date, \"%B %d, %Y\").date()\n",
    "#         movie_dict['language'] = list(releases.nextSibling.nextSibling.children)[1].strip()\n",
    "#         html_page = requests.get('https://www.themoviedb.org/movie/'+ str(movie_id) + '/cast')\n",
    "#         soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "#         div = soup.find('ol', class_='people credits')\n",
    "#         all_divs = div.findAll('div', class_='info')\n",
    "    \n",
    "#         actors = []\n",
    "#         for tag in all_divs:\n",
    "#             actors.append(tag.text.split('\\n')[1])\n",
    "#         movie_dict['actors'] = actors\n",
    "        return movie_dict\n",
    "\n",
    "    movie_info = list(map(scrape_info,less_info))\n",
    "    \n",
    "    def populate_db(records, table_name):\n",
    "#         INSERT_STRING = (\"INSERT INTO {table_name} \"\n",
    "#                    \"(id, vote_average, title, genre_ids, revenue, budget, release_date) \"\n",
    "#                    \"VALUES (%s, %s, %s, %s)\")\n",
    "        INSERT_STR = f'INSERT INTO {table_name} (id, vote_average, title, revenue, budget, release_date) ' \n",
    "        VALUE_STR = 'VALUES (%s, %s, %s, %s, %s, %s)'\n",
    "        INSERT_QUERY = INSERT_STR + VALUE_STR\n",
    "    \n",
    "        for rec in movie_info:\n",
    "            values = tuple(rec.values())\n",
    "            c.execute(INSERT_QUERY, values)\n",
    "        conn.commit()\n",
    "\n",
    "    populate_db(movie_info,'movie_info')\n",
    "c.close()\n",
    "conn.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
